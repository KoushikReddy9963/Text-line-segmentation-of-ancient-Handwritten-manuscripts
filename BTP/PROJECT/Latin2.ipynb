{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1744987682749,
     "user": {
      "displayName": "Berat Kurar",
      "userId": "08116991857459185420"
     },
     "user_tz": -180
    },
    "id": "_2_wdZVKF5uO"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from skimage.morphology import skeletonize\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/koushik/Documents/GitHub/BTP/PROJECT/\")\n",
    "import ani\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1744987682752,
     "user": {
      "displayName": "Berat Kurar",
      "userId": "08116991857459185420"
     },
     "user_tz": -180
    },
    "id": "aMiWVABmFuzi"
   },
   "outputs": [],
   "source": [
    "def estimate_binary_height(binary, th_low, th_high):\n",
    "    labeled = label(binary)\n",
    "    heights = [p.bbox[2] - p.bbox[0]\n",
    "               for p in regionprops(labeled)\n",
    "               if th_low <= (p.bbox[2] - p.bbox[0]) <= th_high]\n",
    "    if not heights:\n",
    "        return None\n",
    "    mu, sigma = np.mean(heights), np.std(heights)\n",
    "    return int(mu - 0.5 * sigma), int(mu + 0.5 * sigma)\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, bin_img = cv2.threshold(gray, 0, 255,\n",
    "                              cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    dilated = cv2.dilate(bin_img, kernel, iterations=1)\n",
    "    return np.bitwise_not(dilated ),dilated\n",
    "\n",
    "def random_label_cmap(num_labels, seed=25):\n",
    "    np.random.seed(seed)\n",
    "    colors = np.random.rand(num_labels, 3)\n",
    "    colors = np.vstack([[0, 0, 0], colors])\n",
    "    return mcolors.ListedColormap(colors)\n",
    "\n",
    "def filter_lines(gray, scales, eta):\n",
    "    responses = []\n",
    "    for scale in scales:\n",
    "        raw = ani.anigauss(\n",
    "            gray.astype(np.float64), sigv=scale, sigu=eta * scale, phi=0, derv=2, deru=0)\n",
    "        responses.append(raw.flatten())\n",
    "    max_resp = np.max(np.array(responses), axis=0).reshape(gray.shape)\n",
    "    thr = np.mean(max_resp) + 0.4 * np.std(max_resp)\n",
    "    return (max_resp > thr).astype(np.uint8) * 255\n",
    "\n",
    "def compute_up_down_distances(binary_image, d):\n",
    "\n",
    "    binary = (binary_image == 0).astype(np.uint8)\n",
    "    h, w = binary.shape\n",
    "\n",
    "    up_dist = np.full((h, w), d, dtype=np.uint16)\n",
    "    down_dist = np.full((h, w), d, dtype=np.uint16)\n",
    "\n",
    "    for i in range(1, d + 1):\n",
    "        shifted = np.zeros_like(binary)\n",
    "        shifted[i:, :] = binary[:-i, :]\n",
    "        mask = (binary == 0) & (shifted == 1)\n",
    "        up_dist[mask] = np.minimum(up_dist[mask], i)\n",
    "    for i in range(1, d + 1):\n",
    "        shifted = np.zeros_like(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18026,
     "status": "ok",
     "timestamp": 1744987700779,
     "user": {
      "displayName": "Berat Kurar",
      "userId": "08116991857459185420"
     },
     "user_tz": -180
    },
    "id": "OWdirFllb_C7",
    "outputId": "2b19fea2-cfc2-4748-af85-7aada518f2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 113.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./113.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./113.png\n",
      "\n",
      "Processing: 103.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./103.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./103.png\n",
      "\n",
      "Processing: 232.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./232.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./232.png\n",
      "\n",
      "Processing: 144.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./144.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./144.png\n",
      "\n",
      "Processing: 108.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./108.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./108.png\n",
      "\n",
      "Processing: 167.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./167.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./167.png\n",
      "\n",
      "Processing: 077.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./077.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./077.png\n",
      "\n",
      "Processing: 231.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./231.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./231.png\n",
      "\n",
      "Processing: 097.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./097.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./097.png\n",
      "\n",
      "Processing: 037.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./037.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./037.png\n"
     ]
    }
   ],
   "source": [
    "input_folders = [\n",
    "    \"/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/img-Latin2/validation/\"\n",
    "]\n",
    "\n",
    "binary_output_root = \"/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/\"\n",
    "color_output_root = \"/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/\"\n",
    "\n",
    "for folder in input_folders:\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if not file.lower().endswith(\".jpg\"):\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nProcessing: {file}\")\n",
    "            image_path = os.path.join(root, file)\n",
    "\n",
    "            # Construct a mirrored output path\n",
    "            relative_path = os.path.relpath(root, start=input_folders[0])\n",
    "            binary_out_dir = os.path.join(binary_output_root, relative_path)\n",
    "            color_out_dir = os.path.join(color_output_root, relative_path)\n",
    "            os.makedirs(binary_out_dir, exist_ok=True)\n",
    "            os.makedirs(color_out_dir, exist_ok=True)\n",
    "            out_path_color = os.path.join(color_out_dir, os.path.splitext(file)[0] + \".png\")\n",
    "            out_path_binary = os.path.join(binary_out_dir, os.path.splitext(file)[0] + \".png\")\n",
    "\n",
    "            # 1) Load and preprocess\n",
    "            bin, inv_bin = load_and_preprocess_image(image_path)\n",
    "\n",
    "            # 2) Estimate character height range\n",
    "            th_low = bin.shape[0] * 0.001\n",
    "            th_high = bin.shape[0] * 0.1\n",
    "            height_range = estimate_binary_height(inv_bin, th_low, th_high)\n",
    "\n",
    "            # 3) Generate line masks\n",
    "            scales = [height_range[0], height_range[1]]\n",
    "            lines_mask = filter_lines(bin, scales, eta=2)\n",
    "\n",
    "            if lines_mask is None or lines_mask.size == 0:\n",
    "                print(\"Empty lines_mask, skipping...\")\n",
    "                continue\n",
    "\n",
    "            v_separators = compute_up_down_distances(255 - lines_mask, 10 * height_range[0])\n",
    "            if v_separators is None or v_separators.size == 0:\n",
    "                # print(\"Empty v_separators, replacing with zeros.\")\n",
    "                v_separators = np.zeros_like(lines_mask, dtype=np.uint8)\n",
    "\n",
    "            inverted_v_separators = cv2.bitwise_not(v_separators)\n",
    "\n",
    "            # Ensure both arrays have the same shape\n",
    "            if inverted_v_separators.shape != lines_mask.shape:\n",
    "                print(f\"Shape mismatch: lines_mask {lines_mask.shape}, inverted_v_separators {inverted_v_separators.shape}\")\n",
    "                inverted_v_separators = cv2.resize(inverted_v_separators, (lines_mask.shape[1], lines_mask.shape[0]),\n",
    "                                                   interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # AND operation\n",
    "            lines_mask_split = cv2.bitwise_and(lines_mask.astype(np.uint8), inverted_v_separators.astype(np.uint8))\n",
    "\n",
    "            # 4) Detect center of lines\n",
    "            bw = lines_mask_split > 0\n",
    "            lines_mask_skel = skeletonize(bw).astype(np.uint8) * 255\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 5))\n",
    "            lines_mask_thick = cv2.dilate(lines_mask_skel, kernel, iterations=1)\n",
    "\n",
    "            # Filter short blob lines\n",
    "            num_lab, labels, stats, _ = cv2.connectedComponentsWithStats(lines_mask_thick, connectivity=8)\n",
    "            lines = np.zeros_like(lines_mask_skel)\n",
    "            for lbl in range(1, num_lab):\n",
    "                width = stats[lbl, cv2.CC_STAT_WIDTH]\n",
    "                height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "                if width >= 20 * height_range[0] and height <= 10 * height_range[0]:\n",
    "                    lines[labels == lbl] = 255\n",
    "\n",
    "            # 5) Dilate lines region\n",
    "            d = int(2 * height_range[0])\n",
    "            kern_ellipse = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * d + 1, 2 * d + 1))\n",
    "            dilated = cv2.dilate(lines.astype(np.uint8), kern_ellipse)\n",
    "\n",
    "            # 6) Final intersection with binary image\n",
    "            final_mask = (((dilated > 0) & (inv_bin > 0)) * 255).astype(np.uint8)\n",
    "\n",
    "            # 7) Watershed segmentation\n",
    "            lines_bool = lines > 0\n",
    "            markers = label(lines_bool)\n",
    "            distance = ndi.distance_transform_edt(lines_bool)\n",
    "            final_mask_bool = final_mask > 0\n",
    "            combined = lines_bool | final_mask_bool\n",
    "            segmented_lines = watershed(image=distance, markers=markers, mask=combined, watershed_line=True, connectivity=2)\n",
    "\n",
    "            # Use a random label colormap\n",
    "            num_labels = int(segmented_lines.max()) + 1\n",
    "            cmap = random_label_cmap(num_labels, seed=25)\n",
    "\n",
    "            # Save color output\n",
    "            plt.imsave(out_path_color, segmented_lines, cmap=cmap)\n",
    "\n",
    "            # Save binary output\n",
    "            cv2.imwrite(out_path_binary, (segmented_lines > 0).astype(np.uint8) * 255)\n",
    "\n",
    "            print(f\"Saved -> {out_path_binary}, {out_path_color}\")\n",
    "\n",
    "\n",
    "# Utility for dataset (unchanged)\n",
    "def get_image_and_gt_paths(base_dir, img_subdir, gt_subdir, split):\n",
    "    img_dir = os.path.join(base_dir, img_subdir, split)\n",
    "    gt_dir = os.path.join(base_dir, gt_subdir, split)\n",
    "    img_paths = sorted([os.path.join(img_dir, fname) for fname in os.listdir(img_dir) if fname.endswith('.jpg')])\n",
    "    gt_paths = sorted([os.path.join(gt_dir, fname) for fname in os.listdir(gt_dir) if fname.endswith('.png')])\n",
    "    return img_paths, gt_paths\n",
    "\n",
    "\n",
    "base_dir = '/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2'\n",
    "img_subdir = 'img-Latin2'\n",
    "gt_subdir = 'text-line-gt-Latin2'\n",
    "split = 'validation'\n",
    "img_paths, gt_paths = get_image_and_gt_paths(base_dir, img_subdir, gt_subdir, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1744987701429,
     "user": {
      "displayName": "Berat Kurar",
      "userId": "08116991857459185420"
     },
     "user_tz": -180
    },
    "id": "MBwcCjUExzt2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Silvia Zottin\n",
    "Evaluation code for FEST 2025: few shot text line segmentation ICDAR 2025 competition.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def get_mask(path, filename, binarize=True):\n",
    "    # retrieving the corresponding mask based on the input path and filename\n",
    "    mask_path = os.path.join(path, filename)\n",
    "    mask_path = os.path.splitext(mask_path)[0] + \".png\"\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # if the flag is true binarize the image before returning it\n",
    "    if binarize:\n",
    "        _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def calculate_IoU(component1, component2):\n",
    "    intersection = np.logical_and(component1, component2).sum()\n",
    "    union = np.logical_or(component1, component2).sum()\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def find_best_matches(gt_components, pred_components, num_gt, num_pred):\n",
    "    matches = []\n",
    "    matches_all = []\n",
    "    for gt_label in range(1, num_gt):\n",
    "        best_iou = 0\n",
    "        best_match = -1\n",
    "        gt_mask = (gt_components == gt_label)\n",
    "\n",
    "        for pred_label in range(1, num_pred):\n",
    "            pred_mask = (pred_components == pred_label)\n",
    "            iou = calculate_IoU(gt_mask, pred_mask)\n",
    "\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_match = pred_label\n",
    "\n",
    "            if iou >= 0.75:\n",
    "                matches_all.append((gt_label, pred_label))\n",
    "\n",
    "        if best_match != -1:\n",
    "            matches.append((gt_label, best_match))\n",
    "\n",
    "    return matches, matches_all\n",
    "\n",
    "\n",
    "def calculate_pixel_and_line_IU(gt_components, pred_components, matches, threshold=0.75):\n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    CL, ML, EL = 0, 0, 0\n",
    "\n",
    "    for gt_label, pred_label in matches:\n",
    "        gt_mask = (gt_components == gt_label)\n",
    "        pred_mask = (pred_components == pred_label)\n",
    "\n",
    "        tp = np.logical_and(gt_mask, pred_mask).sum()\n",
    "        fp = np.logical_and(np.logical_not(gt_mask), pred_mask).sum()\n",
    "        fn = np.logical_and(gt_mask, np.logical_not(pred_mask)).sum()\n",
    "\n",
    "        TP += tp\n",
    "        FP += fp\n",
    "        FN += fn\n",
    "\n",
    "        precision = precision_score(np.array(gt_mask).flatten(), np.array(pred_mask).flatten(), zero_division=0)\n",
    "        recall = recall_score(np.array(gt_mask).flatten(), np.array(pred_mask).flatten(), zero_division=0)\n",
    "\n",
    "\n",
    "        if precision >= threshold and recall >= threshold:\n",
    "            CL += 1\n",
    "        elif recall < threshold:\n",
    "            ML += 1\n",
    "        elif precision < threshold:\n",
    "            EL += 1\n",
    "\n",
    "    pixel_IU = 0 if (TP + FP + FN) == 0 else TP / (TP + FP + FN)\n",
    "    line_IU = 0 if (CL + ML + EL) == 0 else CL / (CL + ML + EL)\n",
    "    print(\"TP: \", TP)\n",
    "    print(\"FP: \", FP)\n",
    "    print(\"FN: \", FN)\n",
    "    print(\"pixel_IU: \", pixel_IU)\n",
    "    print(\"CL: \", CL)\n",
    "    print(\"ML: \", ML)\n",
    "    print(\"EL: \", EL)\n",
    "    print(\"line_IU: \", line_IU)\n",
    "\n",
    "    return pixel_IU, line_IU\n",
    "\n",
    "\n",
    "def evaluate_metrics(gt_img, pred_img):\n",
    "    num_gt, gt_components = cv2.connectedComponents(gt_img)\n",
    "    num_pred, pred_components = cv2.connectedComponents(pred_img)\n",
    "\n",
    "    matches, matches_all = find_best_matches(gt_components, pred_components, num_gt, num_pred)\n",
    "    pixel_IU, line_IU = calculate_pixel_and_line_IU(gt_components, pred_components, matches)\n",
    "\n",
    "    N1 = num_gt - 1\n",
    "    N2 = num_pred - 1\n",
    "\n",
    "    M = len(matches_all)\n",
    "\n",
    "    DR = 0 if N1 == 0 else M / N1\n",
    "    RA = 0 if N1 == 0 else M / N2\n",
    "    FM = 0 if DR + RA == 0 else 2 * (DR * RA) / (DR + RA)\n",
    "\n",
    "    return pixel_IU, line_IU, DR, RA, FM\n",
    "\n",
    "\n",
    "def udiads_textline_evaluate(result_directory, gt_directory):\n",
    "    \"\"\"\n",
    "    Evaluate the results provided by the files in result_directory with respect\n",
    "    to the ground truth information given by the files in gt_directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check whether result_directory and gt_directory are directories\n",
    "    if not os.path.isdir(result_directory):\n",
    "        print(\"The result folder is not a directory\")\n",
    "        return\n",
    "\n",
    "    if not os.path.isdir(gt_directory):\n",
    "        print(\"The gt folder is not a directory\")\n",
    "        return\n",
    "\n",
    "    pixel_list = []\n",
    "    line_list = []\n",
    "    DR_list = []\n",
    "    RA_list = []\n",
    "    FM_list = []\n",
    "    # For each file of the ground truth directory read the result\n",
    "    for f in sorted(os.listdir(gt_directory)):\n",
    "        # retrieving binarized gt and predicted mask\n",
    "        segmentation_bin = get_mask(result_directory, f)\n",
    "        ground_truth_bin = get_mask(gt_directory, f)\n",
    "\n",
    "        # calculating IoU based metrics\n",
    "        print(\"Calculating metrics...\")\n",
    "        pixel_IU, line_IU, DR, RA, FM = evaluate_metrics(ground_truth_bin, segmentation_bin)\n",
    "        pixel_list.append(pixel_IU)\n",
    "        line_list.append(line_IU)\n",
    "        DR_list.append(DR)\n",
    "        RA_list.append(RA)\n",
    "        FM_list.append(FM)\n",
    "\n",
    "        # print perâ€‘page results\n",
    "        print(\n",
    "            f\"[{f}] \"\n",
    "            f\"Pixel IU: {pixel_IU:.4f}, \"\n",
    "            f\"Line IU: {line_IU:.4f}, \"\n",
    "            f\"DR: {DR:.4f}, \"\n",
    "            f\"RA: {RA:.4f}, \"\n",
    "            f\"F-measure: {FM:.4f}\"\n",
    "        )\n",
    "\n",
    "    return np.mean(pixel_list), np.mean(line_list), np.mean(DR_list), np.mean(RA_list), np.mean(FM_list)\n",
    "\n",
    "# If there are any paths, update to local Linux paths\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 842260,
     "status": "ok",
     "timestamp": 1744988543691,
     "user": {
      "displayName": "Berat Kurar",
      "userId": "08116991857459185420"
     },
     "user_tz": -180
    },
    "id": "-BJ5qtkayBEr",
    "outputId": "0d257021-a096-4f96-ba5f-27ddd28a1084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "TP:  360543\n",
      "FP:  63870\n",
      "FN:  44630\n",
      "pixel_IU:  0.7686779250516477\n",
      "CL:  98\n",
      "ML:  4\n",
      "EL:  3\n",
      "line_IU:  0.9333333333333333\n",
      "[037.png] Pixel IU: 0.7687, Line IU: 0.9333, DR: 0.7928, RA: 0.8381, F-measure: 0.8148\n",
      "Calculating metrics...\n",
      "TP:  345550\n",
      "FP:  38323\n",
      "FN:  63184\n",
      "pixel_IU:  0.7729439422713434\n",
      "CL:  94\n",
      "ML:  8\n",
      "EL:  1\n",
      "line_IU:  0.912621359223301\n",
      "[077.png] Pixel IU: 0.7729, Line IU: 0.9126, DR: 0.7156, RA: 0.7647, F-measure: 0.7393\n",
      "Calculating metrics...\n",
      "TP:  150588\n",
      "FP:  24240\n",
      "FN:  81061\n",
      "pixel_IU:  0.588489540386652\n",
      "CL:  32\n",
      "ML:  27\n",
      "EL:  0\n",
      "line_IU:  0.5423728813559322\n",
      "[097.png] Pixel IU: 0.5885, Line IU: 0.5424, DR: 0.1864, RA: 0.1122, F-measure: 0.1401\n",
      "Calculating metrics...\n",
      "TP:  344095\n",
      "FP:  42594\n",
      "FN:  49864\n",
      "pixel_IU:  0.788208991806264\n",
      "CL:  104\n",
      "ML:  3\n",
      "EL:  0\n",
      "line_IU:  0.9719626168224299\n",
      "[103.png] Pixel IU: 0.7882, Line IU: 0.9720, DR: 0.8053, RA: 0.8585, F-measure: 0.8311\n",
      "Calculating metrics...\n",
      "TP:  329490\n",
      "FP:  91138\n",
      "FN:  55302\n",
      "pixel_IU:  0.6923076923076923\n",
      "CL:  92\n",
      "ML:  11\n",
      "EL:  9\n",
      "line_IU:  0.8214285714285714\n",
      "[108.png] Pixel IU: 0.6923, Line IU: 0.8214, DR: 0.5952, RA: 0.7500, F-measure: 0.6637\n",
      "Calculating metrics...\n",
      "TP:  343803\n",
      "FP:  60637\n",
      "FN:  47080\n",
      "pixel_IU:  0.761434709425939\n",
      "CL:  97\n",
      "ML:  4\n",
      "EL:  5\n",
      "line_IU:  0.9150943396226415\n",
      "[113.png] Pixel IU: 0.7614, Line IU: 0.9151, DR: 0.8125, RA: 0.8585, F-measure: 0.8349\n",
      "Calculating metrics...\n",
      "TP:  103259\n",
      "FP:  46863\n",
      "FN:  73674\n",
      "pixel_IU:  0.46139788021233624\n",
      "CL:  25\n",
      "ML:  14\n",
      "EL:  31\n",
      "line_IU:  0.35714285714285715\n",
      "[144.png] Pixel IU: 0.4614, Line IU: 0.3571, DR: 0.1538, RA: 0.0902, F-measure: 0.1137\n",
      "Calculating metrics...\n",
      "TP:  247763\n",
      "FP:  101109\n",
      "FN:  44470\n",
      "pixel_IU:  0.6298920532259459\n",
      "CL:  76\n",
      "ML:  8\n",
      "EL:  12\n",
      "line_IU:  0.7916666666666666\n",
      "[167.png] Pixel IU: 0.6299, Line IU: 0.7917, DR: 0.5575, RA: 0.7590, F-measure: 0.6429\n",
      "Calculating metrics...\n",
      "TP:  102151\n",
      "FP:  8404\n",
      "FN:  95048\n",
      "pixel_IU:  0.49683613565949913\n",
      "CL:  34\n",
      "ML:  9\n",
      "EL:  0\n",
      "line_IU:  0.7906976744186046\n",
      "[231.png] Pixel IU: 0.4968, Line IU: 0.7907, DR: 0.5926, RA: 0.5614, F-measure: 0.5766\n",
      "Calculating metrics...\n",
      "TP:  254152\n",
      "FP:  34604\n",
      "FN:  37658\n",
      "pixel_IU:  0.7786185641547237\n",
      "CL:  70\n",
      "ML:  7\n",
      "EL:  2\n",
      "line_IU:  0.8860759493670886\n",
      "[232.png] Pixel IU: 0.7786, Line IU: 0.8861, DR: 0.7711, RA: 0.7711, F-measure: 0.7711\n",
      "Pixel IU:  0.6738807434502043\n",
      "Line IU:  0.7922396249381427\n",
      "Detection Rate:  0.5982922838467444\n",
      "Recognition Accuracy:  0.636377670509225\n",
      "F-measure:  0.6128170256644238\n"
     ]
    }
   ],
   "source": [
    "Pixel_IU, Line_IU, DR, RA, FM = udiads_textline_evaluate(\n",
    "    result_directory=\"/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation\",\n",
    "    gt_directory=\"/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-gt-Latin2/validation\"\n",
    "    )\n",
    "\n",
    "print(\"Pixel IU: \", Pixel_IU)\n",
    "print(\"Line IU: \", Line_IU)\n",
    "print(\"Detection Rate: \", DR)\n",
    "print(\"Recognition Accuracy: \", RA)\n",
    "print(\"F-measure: \", FM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 113.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./113.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./113.png\n",
      "\n",
      "Processing: 103.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./103.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./103.png\n",
      "\n",
      "Processing: 232.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./232.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./232.png\n",
      "\n",
      "Processing: 144.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./144.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./144.png\n",
      "\n",
      "Processing: 108.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./108.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./108.png\n",
      "\n",
      "Processing: 167.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./167.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./167.png\n",
      "\n",
      "Processing: 077.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./077.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./077.png\n",
      "\n",
      "Processing: 231.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./231.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./231.png\n",
      "\n",
      "Processing: 097.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./097.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./097.png\n",
      "\n",
      "Processing: 037.jpg\n",
      "Saved -> /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/./037.png, /home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/./037.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from skimage.morphology import skeletonize\n",
    "import sys\n",
    "sys.path.append(\"/home/koushik/Documents/GitHub/midrash_tauch_submission_icdar2025_fest_textline_segmentation_competition/tauch_submission_icdar2025_fest_textline_segmentation_competition_code_and_results\")\n",
    "import ani\n",
    "\n",
    "def estimate_binary_height(binary, th_low, th_high):\n",
    "    labeled = label(binary)\n",
    "    heights = [p.bbox[2] - p.bbox[0]\n",
    "               for p in regionprops(labeled)\n",
    "               if th_low <= (p.bbox[2] - p.bbox[0]) <= th_high]\n",
    "    if not heights:\n",
    "        return None\n",
    "    mu, sigma = np.mean(heights), np.std(heights)\n",
    "    return int(mu - 0.5 * sigma), int(mu + 0.5 * sigma)\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, bin_img = cv2.threshold(gray, 0, 255,\n",
    "                              cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    dilated = cv2.dilate(bin_img, kernel, iterations=1)\n",
    "    return np.bitwise_not(dilated), dilated\n",
    "\n",
    "def random_label_cmap(num_labels, seed=25):\n",
    "    np.random.seed(seed)\n",
    "    colors = np.random.rand(num_labels, 3)\n",
    "    colors = np.vstack([[0, 0, 0], colors])\n",
    "    return mcolors.ListedColormap(colors)\n",
    "\n",
    "def filter_lines(gray, scales, eta):\n",
    "    responses = []\n",
    "    for scale in scales:\n",
    "        raw = ani.anigauss(\n",
    "            gray.astype(np.float64), sigv=scale, sigu=eta * scale, phi=0, derv=2, deru=0)\n",
    "        responses.append(raw.flatten())\n",
    "    max_resp = np.max(np.array(responses), axis=0).reshape(gray.shape)\n",
    "    thr = np.mean(max_resp) + 0.4 * np.std(max_resp)\n",
    "    return (max_resp > thr).astype(np.uint8) * 255\n",
    "\n",
    "def compute_up_down_distances(binary_image, d):\n",
    "    binary = (binary_image == 0).astype(np.uint8)\n",
    "    h, w = binary.shape\n",
    "    up_dist = np.full((h, w), d, dtype=np.uint16)\n",
    "    down_dist = np.full((h, w), d, dtype=np.uint16)\n",
    "    \n",
    "    for i in range(1, d + 1):\n",
    "        shifted = np.zeros_like(binary)\n",
    "        shifted[i:, :] = binary[:-i, :]\n",
    "        mask = (binary == 0) & (shifted == 1)\n",
    "        up_dist[mask] = np.minimum(up_dist[mask], i)\n",
    "    \n",
    "    for i in range(1, d + 1):\n",
    "        shifted = np.zeros_like(binary)\n",
    "        shifted[:-i, :] = binary[i:, :]\n",
    "        mask = (binary == 0) & (shifted == 1)\n",
    "        down_dist[mask] = np.minimum(down_dist[mask], i)\n",
    "    \n",
    "    return np.minimum(up_dist, down_dist).astype(np.uint8)\n",
    "\n",
    "input_folders = [\n",
    "    \"/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/img-Latin2/validation/\"\n",
    "]\n",
    "\n",
    "binary_output_root = \"/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/validation/\"\n",
    "color_output_root = \"/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2/text-line-prediction-Latin2/colored_validation/\"\n",
    "\n",
    "for folder in input_folders:\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if not file.lower().endswith(\".jpg\"):\n",
    "                continue\n",
    "            print(f\"\\nProcessing: {file}\")\n",
    "            image_path = os.path.join(root, file)\n",
    "            \n",
    "            # Construct a mirrored output path\n",
    "            relative_path = os.path.relpath(root, start=input_folders[0])\n",
    "            binary_out_dir = os.path.join(binary_output_root, relative_path)\n",
    "            color_out_dir = os.path.join(color_output_root, relative_path)\n",
    "            os.makedirs(binary_out_dir, exist_ok=True)\n",
    "            os.makedirs(color_out_dir, exist_ok=True)\n",
    "            \n",
    "            out_path_color = os.path.join(color_out_dir, os.path.splitext(file)[0] + \".png\")\n",
    "            out_path_binary = os.path.join(binary_out_dir, os.path.splitext(file)[0] + \".png\")\n",
    "            \n",
    "            # 1) Load and preprocess\n",
    "            bin, inv_bin = load_and_preprocess_image(image_path)\n",
    "            \n",
    "            # 2) Estimate character height range\n",
    "            th_low = bin.shape[0] * 0.001\n",
    "            th_high = bin.shape[0] * 0.1\n",
    "            height_range = estimate_binary_height(inv_bin, th_low, th_high)\n",
    "            \n",
    "            # 3) Generate line masks\n",
    "            scales = [height_range[0], height_range[1]]\n",
    "            lines_mask = filter_lines(bin, scales, eta=2)\n",
    "            \n",
    "            if lines_mask is None or lines_mask.size == 0:\n",
    "                print(\"Empty lines_mask, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            v_separators = compute_up_down_distances(255 - lines_mask, 10 * height_range[0])\n",
    "            \n",
    "            if v_separators is None or v_separators.size == 0:\n",
    "                print(\"Empty v_separators, replacing with zeros.\")\n",
    "                v_separators = np.zeros_like(lines_mask, dtype=np.uint8)\n",
    "            \n",
    "            inverted_v_separators = cv2.bitwise_not(v_separators)\n",
    "            \n",
    "            # Ensure both arrays have the same shape\n",
    "            if inverted_v_separators.shape != lines_mask.shape:\n",
    "                print(f\"Shape mismatch: lines_mask {lines_mask.shape}, inverted_v_separators {inverted_v_separators.shape}\")\n",
    "                inverted_v_separators = cv2.resize(inverted_v_separators, (lines_mask.shape[1], lines_mask.shape[0]),\n",
    "                                                   interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            # AND operation\n",
    "            lines_mask_split = cv2.bitwise_and(lines_mask.astype(np.uint8), inverted_v_separators.astype(np.uint8))\n",
    "            \n",
    "            # 4) Detect center of lines\n",
    "            bw = lines_mask_split > 0\n",
    "            lines_mask_skel = skeletonize(bw).astype(np.uint8) * 255\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 5))\n",
    "            lines_mask_thick = cv2.dilate(lines_mask_skel, kernel, iterations=1)\n",
    "            \n",
    "            # ONLY MINIMAL IMPROVEMENT: Slightly connect broken segments\n",
    "            if height_range[0] > 5:  # Only if reasonable height\n",
    "                connect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (max(3, height_range[0]//4), 1))\n",
    "                lines_mask_thick = cv2.morphologyEx(lines_mask_thick, cv2.MORPH_CLOSE, connect_kernel)\n",
    "            \n",
    "            # Filter short blob lines - ORIGINAL with slight adjustment\n",
    "            num_lab, labels, stats, _ = cv2.connectedComponentsWithStats(lines_mask_thick, connectivity=8)\n",
    "            lines = np.zeros_like(lines_mask_skel)\n",
    "            for lbl in range(1, num_lab):\n",
    "                width = stats[lbl, cv2.CC_STAT_WIDTH]\n",
    "                height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "                # Keep original filtering but slightly more lenient\n",
    "                if width >= 18 * height_range[0] and height <= 12 * height_range[0]:\n",
    "                    lines[labels == lbl] = 255\n",
    "            \n",
    "            # 5) Dilate lines region\n",
    "            d = int(2 * height_range[0])\n",
    "            kern_ellipse = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * d + 1, 2 * d + 1))\n",
    "            dilated = cv2.dilate(lines.astype(np.uint8), kern_ellipse)\n",
    "            \n",
    "            # 6) Final intersection with binary image - ORIGINAL\n",
    "            final_mask = (((dilated > 0) & (inv_bin > 0)) * 255).astype(np.uint8)\n",
    "            \n",
    "            # 7) Watershed segmentation - ORIGINAL\n",
    "            lines_bool = lines > 0\n",
    "            markers = label(lines_bool)\n",
    "            distance = ndi.distance_transform_edt(lines_bool)\n",
    "            final_mask_bool = final_mask > 0\n",
    "            combined = lines_bool | final_mask_bool\n",
    "            segmented_lines = watershed(image=distance, markers=markers, mask=combined, watershed_line=True, connectivity=2)\n",
    "            \n",
    "            # Use a random label colormap\n",
    "            num_labels = int(segmented_lines.max()) + 1\n",
    "            cmap = random_label_cmap(num_labels, seed=25)\n",
    "            \n",
    "            # Save color output\n",
    "            plt.imsave(out_path_color, segmented_lines, cmap=cmap)\n",
    "            \n",
    "            # Save binary output\n",
    "            cv2.imwrite(out_path_binary, (segmented_lines > 0).astype(np.uint8) * 255)\n",
    "            \n",
    "            print(f\"Saved -> {out_path_binary}, {out_path_color}\")\n",
    "\n",
    "# Utility for dataset (unchanged)\n",
    "def get_image_and_gt_paths(base_dir, img_subdir, gt_subdir, split):\n",
    "    img_dir = os.path.join(base_dir, img_subdir, split)\n",
    "    gt_dir = os.path.join(base_dir, gt_subdir, split)\n",
    "    img_paths = sorted([os.path.join(img_dir, fname) for fname in os.listdir(img_dir) if fname.endswith('.jpg')])\n",
    "    gt_paths = sorted([os.path.join(gt_dir, fname) for fname in os.listdir(gt_dir) if fname.endswith('.png')])\n",
    "    return img_paths, gt_paths\n",
    "\n",
    "base_dir = '/home/koushik/Documents/GitHub/BTP/PROJECT/Latin2'\n",
    "img_subdir = 'img-Latin2'\n",
    "gt_subdir = 'text-line-gt-Latin2'\n",
    "split = 'validation'\n",
    "\n",
    "img_paths, gt_paths = get_image_and_gt_paths(base_dir, img_subdir, gt_subdir, split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line IU:  0.7889348718596964\n",
    "# Detection Rate:  0.6000781404998575\n",
    "# Recognition Accuracy:  0.623199662047739\n",
    "# F-measure:  0.6062658492267865\n",
    "\n",
    "# Line IU:  0.7922396249381427\n",
    "# Detection Rate:  0.5982922838467444\n",
    "# Recognition Accuracy:  0.636377670509225\n",
    "# F-measure:  0.6128170256644238"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOvuUB+TbjpWPiPnViV6FI0",
   "machine_shape": "hm",
   "mount_file_id": "1dWi-bFlBmfxyMTscCId-PTcqEitXkoPt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
